# Create Simulations
#' Generate simulations for comparison
#'
#' This function generates a dataframe containing multiple simulations of random data.
#'
#' The tests of this package rely on comparisons of the experimental data to simulated random data sets.
#' This function can provide a dataframe containing multiple simulated runs of the experiment with completely random data.
#' To generate the random data a software-based pseudo-RNG can be used or - better - the package provides text-files containing random bit sequences previously generated by a quantum-based trueRNG (Quantis).
#' Simulations can be created for binomial datasets and bits can be summed up to represent normally distributed mean scores.
#'
#' @param trials The amount of trials in a single experiment (this includes all subjects).
#' @param n.sims The amount of simulations to be generated. 10,000 is recommended, this might take several hours or days, though, depending on the sample size and number of trials.
#' @param mean.scores Should bits be summed up to represent a normal distribution centered about a mean? If yes, indicate the desired mean score here. If you are comparing to binomial data, set to NULL.
#' @param use.files Should the random data be taken out of the tRNG files (TRUE) or should new data be generated? (FALSE).
#' @param use.quantis If use.files = FALSE, should the new data be generated by a pseudoRNG (FALSE) or by a Quantis QRNG via the EasyQuantis application (TRUE)?
#' @param filespath If random files should be used indicate the path to those files.
#' @param parallel If set to TRUE, multiple cores are being used in parallel to generate the simulations (recommenden).
#' @param nstart Number of data points that are considered before calculating the first BF (min = 2)
#' @param alternative Set parameter for Bayesian testing (t-Test).
#' @param prior.loc Set parameter for Bayesian testing (t-Test).
#' @param prior.r Set parameter for Bayesian testing.
#' @param p Set parameter for Bayesian testing (Binomial) or data generation for probabilities of success other than 0.5.
#' @return A dataframe with trials*nsims rows containing the columns "simid","index","rw","density.rw","bf" and "density.bf".
#' @examples
#' sims <- simcreate(100)
#' sims1000 <- simcreate(100, n.sims = 1000)
#' sims <- simcreate(600, mean.scores = 30)
#' sims.pseudo <- simcreate(2000, use.files = FALSE)
#' @export

simcreate <- function(trials, n.sims = 1000, mean.scores = NULL, use.files = TRUE, use.quantis = FALSE, filespath = "RandomFiles/", parallel = TRUE, nstart = 5, alternative = c("two.sided", "less", "greater"), prior.loc = 0, prior.r = 0.1, p = 0.5){
  if(nstart <= 2) stop("Please use a larger nstart. Testing requires a certain amount of variance in the data.")
  if(nstart < 5) warning("Consider using a larger nstart. Data aggregation was repeated until the selected data contained variance. Still, this process is not ideal.")
  if(!is.null(mean.scores)){
    if((trials/mean.scores) - round(trials/mean.scores) != 0) stop("Mean.scores should be a divisor of trials")
  }
  maxbit <- (1/p)-1
  
  require(foreach)
  require(doParallel)
  
  u.trials <- trials
  print("Generating Simulations...")
  
  if(parallel == TRUE){
    print("This will probably take a while. See log.txt for status updates!")
    #setup parallel backend to use many processors
    cores=detectCores()
    cl <- makeCluster(cores[1]-1) #not to overload your computer
    registerDoParallel(cl)
    
    if(use.files == TRUE){ # Use .txt files from folder
      rfiles <- list.files(filespath, full.names = TRUE, pattern="*.txt")
      if (length(rfiles) == 0) stop("No random files found! Did you specify the correct folder? Did you provide .txt-Files?")
      if (length(rfiles) < n.sims) stop("Number of simulations is larger than amount of random files!")
    }
    
    sim.out <- foreach(i=1:n.sims, .combine=rbind) %dopar% {
      sink("log.txt", append = TRUE)
      cat(paste(Sys.time(),"Starting iteration",i,"\n"))
      sink()
      
      if(use.files == TRUE){
        # read txt
        
        simf <- read.table(rfiles[i])
        if(trials > nrow(simf)) stop("Number of trials is larger than amount of random bits per file!")
        if(trials == nrow(simf)) sim <- data.frame(V1=simf)
        if(trials < nrow(simf)){
          line.start <- sample.int(nrow(simf)-(u.trials),1)
          line.stop <- line.start+u.trials-1
          sim <- data.frame(V1=simf[line.start:line.stop,])
        }
        
      } else { # fresh numbers
        
        if(use.quantis == TRUE){ # quantis QRNG
          #if("tmp.txt" %in% list.files()) unlink("tmp.txt")
          #system(paste0('EasyQuantis -u 0 -n ',u.trials,' --min 0 --max 1 -i "tmp.txt"'))
          #if("tmp.txt" %in% list.files()) {
          #  sim <- read.table("tmp.txt")
          #} else stop("Could not create random bits from QRNG. Is the device connected? Consider using use.quantis = FALSE.")
          stop("Please use parallel = FALSE when generating fresh Quantis numbers.")
        } else { # psuedo RNG
          sim <- data.frame(V1=rbinom(u.trials, 1, p))
        }
        
      }
      
      if(!is.null(mean.scores)){
        # group bits
        sim$group = rep(1:(nrow(sim)/(mean.scores*(1/p))), each=mean.scores*(1/p))
        # 0 is winner (1), rest is loser (0) for cases where there are more than 2 bits (p != 0.5)
        if(p != 0.5) sim[,1] <- ifelse(sim[,1] == 0, 1, 0)
        #sum up bits
        sim <- tapply(sim[,1], sim$group, FUN = sum)
        if(var(sim[1:nstart]) == 0) repeat{ #repeat reading data until variance is not 0 so t-test will work
          if(use.files == TRUE){
            if(trials == nrow(simf)) stop("Not enough variance in data. Use larger simfiles.")
            line.start <- sample.int(nrow(simf)-(u.trials),1)
            line.stop <- line.start+u.trials-1
            sim <- data.frame(V1=simf[line.start:line.stop,])
            sim$group = rep(1:(nrow(sim)/(mean.scores*(1/p))), each=mean.scores*(1/p))
            sim <- tapply(sim[,1], sim$group, FUN = sum)
          } else {
            sim <- data.frame(V1=rbinom(u.trials, 1, p))
          }
          if(var(sim[1:nstart]) != 0) break
        }
        sim <- data.frame(sums=sim)
        sim$cumsum <- cumsum(sim$sums-mean.scores)
        
        # BAYES t TEST
        sim$bf <- changeofevidence::bfttest(sim$sums, alternative = alternative, mu = mean.scores, prior.loc = prior.loc, prior.r = prior.r, nstart = nstart)$BF
        
      } else {
        sim$qbitmin1 <- ifelse(sim[,1] == 0, -1, 1)
        sim$cumsum <- cumsum(sim$qbitmin1)
        
        #(2) BAYES BINOM TEST
        sim$bf <- changeofevidence::bfbinom(sim$V1, p = p, prior.r = prior.r, nstart = nstart)
      }
      
      # Run FFT on Random Walk
      L <- length(sim$cumsum) # Länge
      T <- 1/L # Tastrate
      Y <- fft(sim$cumsum) # Fast Fourier Transformation
      P <- abs(Y/L)
      
      # Run FFT on Bayes Test
      Y2 <- fft(sim$bf) # Fast Fourier Transformation
      P2 <- abs(Y2/L)
      
      # Write results to Matrix
      index <- as.numeric(1:L)
      tempMatrix <- data.frame(simid=i, index=index, raw=sim[,1], rw=sim$cumsum, density.rw=P, bf=sim$bf, density.bf=P2)
      
      tempMatrix #Equivalent to finalMatrix = cbind(finalMatrix, tempMatrix)
    }
    
    
    #stop cluster
    stopCluster(cl)
    #colnames(sim.out) <- c("simid","index","raw","rw","density.rw","bf","density.bf")
  } else{
    # Parallel = FALSE
    sim.out <- list()
    
    for(i in 1:n.sims){
      cat("Sim",i,"of",n.sims,"\n")
      
      if(use.files == TRUE){
        rfiles <- list.files(filespath, full.names = TRUE, pattern="*.txt")
        if (length(rfiles) == 0) stop("No random files found! Did you specify the correct folder? Did you provide .txt-Files?")
        if (length(rfiles) < n.sims) stop("Number of simulations is larger than amount of random files!")
      
        simf <- read.table(rfiles[i])
        if(trials > nrow(simf)) stop("Number of trials is larger than amount of random bits per file!")
        if(trials == nrow(simf)) sim <- data.frame(V1=simf)
        if(trials < nrow(simf)){
          line.start <- sample.int(nrow(simf)-(u.trials),1)
          line.stop <- line.start+u.trials-1
          sim <- data.frame(V1=simf[line.start:line.stop,])
        }
      
      } else { # don't use files
        
        if(use.quantis == TRUE){ # quantis QRNG
          if("tmp.txt" %in% list.files()) unlink("tmp.txt")
          system(paste0('EasyQuantis -u 0 -n ',u.trials,' --min 0 --max ',maxbit,' -i "tmp.txt"'))
          if("tmp.txt" %in% list.files()) {
            sim <- read.table("tmp.txt")
          } else stop("Could not create random bits from QRNG. Is the device connected? Consider using use.quantis = FALSE.")
        } else { # psuedo RNG
          sim <- data.frame(V1=rbinom(u.trials, 1, p))
        }
        
      }
    
      if(!is.null(mean.scores)){
        # group bits
        sim$group = rep(1:(nrow(sim)/(mean.scores*(1/p))), each=mean.scores*(1/p))
        # 0 is winner (1), rest is loser (0) for cases where there are more than 2 bits (p != 0.5)
        if(p != 0.5) sim[,1] <- ifelse(sim[,1] == 0, 1, 0)
        #sum up bits
        sim <- tapply(sim[,1], sim$group, FUN = sum)
        if(var(sim[1:nstart]) == 0) repeat{ #repeat reading data until variance is not 0 so t-test will work
          if(use.files == TRUE){
            if(trials == nrow(simf)) stop("Not enough variance in data. Use larger simfiles.")
            line.start <- sample.int(nrow(simf)-(u.trials),1)
            line.stop <- line.start+u.trials-1
            sim <- data.frame(V1=simf[line.start:line.stop,])
            sim$group = rep(1:(nrow(sim)/(mean.scores*(1/p))), each=mean.scores*(1/p))
            sim <- tapply(sim[,1], sim$group, FUN = sum)
          } else {
            sim <- data.frame(V1=rbinom(u.trials, 1, p))
          }
          if(var(sim[1:nstart]) != 0) break
        }
        sim$cumsum <- cumsum(sim$sums-mean.scores)
        
        # BAYES t TEST
        sim$bf <- changeofevidence::bfttest(sim$sums, alternative = alternative, mu = mean.scores, prior.loc = prior.loc, prior.r = prior.r, nstart = nstart)$BF
        
        
      } else {
        sim$qbitmin1 <- ifelse(sim[,1] == 0, -1, 1)
        sim$cumsum <- cumsum(sim$qbitmin1)
        
        #(2) BAYES BINOM TEST
        sim$bf <- changeofevidence::bfbinom(sim$V1, p = p, prior.r = prior.r, nstart = nstart)
      }
      
      # Run FFT on Random Walk
      L <- length(sim$cumsum) # Länge
      T <- 1/L # Tastrate
      Y <- fft(sim$cumsum) # Fast Fourier Transformation
      P <- abs(Y/L)
      
      # Run FFT on Bayes Test
      Y2 <- fft(sim$bf) # Fast Fourier Transformation
      P2 <- abs(Y2/L)
      
      # Write results to Matrix
      index <- as.numeric(1:L)
      tempMatrix <- data.frame(simid=i, index=index, raw=sim[,1], rw=sim$cumsum, density.rw=P, bf=sim$bf, density.bf=P2)
      
      sim.out[[i]] <- tempMatrix
      
    }
    
    sim.out <- dplyr::bind_rows(sim.out)
  }
  
  return(sim.out)
}
